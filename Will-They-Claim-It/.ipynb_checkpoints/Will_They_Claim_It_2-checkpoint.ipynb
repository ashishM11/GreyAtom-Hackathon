{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "\n",
    "Insurance companies take risks over customers. Risk management is a very important aspect of the insurance industry. Insurers consider every quantifiable factor to develop profiles of high and low insurance risks. Insurers collect vast amounts of information about policyholders and analyze the data.\n",
    "\n",
    "<u>As a Data scientist in an insurance company, you need to analyze the available data and predict whether to sanction the insurance or not</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported required packages for analysis and model creation.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imported data using pandas library\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>61</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4245</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>4</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9251</td>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>26</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>15</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8840</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>15</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5959</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>4</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6031</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>215</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8394</td>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>31</td>\n",
       "      <td>VIET NAM</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3017</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>13</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>48.662699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8054</td>\n",
       "      <td>C2B</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Bronze Plan</td>\n",
       "      <td>10</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>23.258824</td>\n",
       "      <td>5.817294</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID Agency    Agency Type Distribution Channel  \\\n",
       "0  2010    EPX  Travel Agency               Online   \n",
       "1  4245    EPX  Travel Agency               Online   \n",
       "2  9251    CWT  Travel Agency               Online   \n",
       "3  4754    EPX  Travel Agency               Online   \n",
       "4  8840    EPX  Travel Agency               Online   \n",
       "5  5959    EPX  Travel Agency               Online   \n",
       "6  6031    EPX  Travel Agency               Online   \n",
       "7  8394    JZI       Airlines               Online   \n",
       "8  3017    EPX  Travel Agency               Online   \n",
       "9  8054    C2B       Airlines               Online   \n",
       "\n",
       "                      Product Name  Duration     Destination  Net Sales  \\\n",
       "0                Cancellation Plan        61     PHILIPPINES  12.000000   \n",
       "1                Cancellation Plan         4        MALAYSIA  17.000000   \n",
       "2  Rental Vehicle Excess Insurance        26        THAILAND  19.800000   \n",
       "3         2 way Comprehensive Plan        15       HONG KONG  27.000000   \n",
       "4         2 way Comprehensive Plan        15        MALAYSIA  37.000000   \n",
       "5         2 way Comprehensive Plan         4        THAILAND  25.000000   \n",
       "6                Cancellation Plan       215  UNITED KINGDOM  59.000000   \n",
       "7                       Basic Plan        31        VIET NAM  22.000000   \n",
       "8         2 way Comprehensive Plan        13           CHINA  48.662699   \n",
       "9                      Bronze Plan        10       SINGAPORE  23.258824   \n",
       "\n",
       "   Commision (in value)  Age  Claim  \n",
       "0              0.000000   41      0  \n",
       "1              0.000000   35      0  \n",
       "2             11.880000   47      0  \n",
       "3              0.000000   48      0  \n",
       "4              0.000000   36      0  \n",
       "5              0.000000   38      0  \n",
       "6              0.000000   36      0  \n",
       "7              7.700000   43      0  \n",
       "8              0.000000   36      1  \n",
       "9              5.817294   28      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One glance at imported data set\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52310 entries, 0 to 52309\n",
      "Data columns (total 11 columns):\n",
      "ID                      52310 non-null int64\n",
      "Agency                  52310 non-null object\n",
      "Agency Type             52310 non-null object\n",
      "Distribution Channel    52310 non-null object\n",
      "Product Name            52310 non-null object\n",
      "Duration                52310 non-null int64\n",
      "Destination             52310 non-null object\n",
      "Net Sales               52310 non-null float64\n",
      "Commision (in value)    52310 non-null float64\n",
      "Age                     52310 non-null int64\n",
      "Claim                   52310 non-null int64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# finding meta info about loaded dataset\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manchine Learning steps:\n",
    "\n",
    "    1.Data Pre-Processing & Exploratory Data Analysis\n",
    "    2.Feature Selection Pipeline\n",
    "    3.Model Creation\n",
    "    4.Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (A) <u>Data Pre-Processing and Exploratory Data Analysis</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: finding any missing values and data types\n",
    "\n",
    "def check_data_missing_columns(dataframe):\n",
    "    data_missing_columns = [col for col in train_df.columns if train_df[col].isnull().sum() > 0]\n",
    "    if len(data_missing_columns) == 0:\n",
    "        print(\"No Data missing from Dataset.\")\n",
    "    else:\n",
    "        print(\"Data missing in columns : \",\",\".join(data_missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Data is not missing now verifying the columns and its type\n",
    "def get_numeric_and_non_numeric_columns(dataframe):\n",
    "    numeric_df = dataframe.select_dtypes(include=np.number)\n",
    "    non_numeric_df = dataframe.select_dtypes(exclude=np.number)\n",
    "    return numeric_df,non_numeric_df\n",
    "    \n",
    "numeric_df, non_numeric_df = get_numeric_and_non_numeric_columns(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'Duration', 'Net Sales', 'Commision (in value)', 'Age', 'Claim']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric Dataframe\n",
    "list(numeric_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Numeric Dataframe\n",
    "non_numeric_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value_counts(categorical_df):\n",
    "    for col in categorical_df.columns:\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.title('Distribution of {}'.format(col))\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Value Counts')\n",
    "        ax = (categorical_df[col].value_counts()/len(categorical_df)*100).sort_index().plot(kind=\"bar\", rot=90)\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_yticks(np.arange(0, 110, 10)*len(categorical_df)/100)\n",
    "        plt.show()\n",
    "            \n",
    "check_value_counts(non_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Determinig the X & Y for the given dataset.\n",
    "X = final_df.iloc[:,0:-1]\n",
    "y = final_df.Claim\n",
    "\n",
    "#importing model_selection package from sklearn\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# Determine X_train,X_test,y_train,y_test\n",
    "X_train, X_test, y_train, y_test = tts(X,y,test_size=0.23,random_state=42)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modification_in_destination_feature(non_numeric_df):\n",
    "    bool_series = non_numeric_df.Destination.value_counts() < 500\n",
    "    temp_df = pd.DataFrame(bool_series)\n",
    "    destination_list = list(temp_df[temp_df.Destination==True].index)\n",
    "    for destination in destination_list:\n",
    "        non_numeric_df.Destination = non_numeric_df.Destination.replace(destination,'OTHER')\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    chart = sns.countplot(x='Destination', data=non_numeric_df)\n",
    "    chart.set_xticklabels(\n",
    "        chart.get_xticklabels(), \n",
    "        rotation=45, \n",
    "        horizontalalignment='right',\n",
    "        fontweight='light',\n",
    "        fontsize='x-large'\n",
    "    )\n",
    "    \n",
    "    return non_numeric_df\n",
    "    \n",
    "non_numeric_df = modification_in_destination_feature(non_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Performing feature scaling on numeric columns before that droping ID column from numeri_df.\n",
    "def apply_scaling_numeric(numeric_df):\n",
    "    numeric_df.drop(columns=['ID'],axis=1,inplace=True)\n",
    "    # Importing Data pre-process library from Sk-Learn\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    # initialize MinMaxScaler \n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    # Extracting features names, because after applying fit_transform dataframe converted to ndarray\n",
    "    numeric_df_columns = numeric_df.columns\n",
    "    \n",
    "    #Applying fit transform on numeric dataframe.\n",
    "    numeric_df = min_max_scaler.fit_transform(numeric_df)\n",
    "\n",
    "    # Converting from ndarray to dataframe\n",
    "    return pd.DataFrame(numeric_df,columns=numeric_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = apply_scaling_numeric(numeric_df)\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_onehot_encoding(categorical_df):\n",
    "    for col in categorical_df.columns:\n",
    "        cat_col = pd.get_dummies(categorical_df[col],drop_first=True)\n",
    "        categorical_df = categorical_df.drop(col,axis=1)\n",
    "        categorical_df = pd.concat([cat_col,categorical_df],axis=1)\n",
    "    return categorical_df\n",
    "\n",
    "non_numeric_df = perform_onehot_encoding(non_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_df(non_numeric_df,numeric_df):\n",
    "    return pd.concat([non_numeric_df,numeric_df],axis=1)\n",
    "\n",
    "final_df = generate_final_df(non_numeric_df,numeric_df)\n",
    "print(len(final_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_forest():\n",
    "    #Import Random Forest Model\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    #Create a Gaussian Classifier\n",
    "    parameters = {'max_depth': [10, 50, 100, 200 ,300, 500], 'n_estimators' :[40,50,70,90]}\n",
    "    clftree = RandomForestClassifier(class_weight='balanced')\n",
    "    clf = GridSearchCV(clftree,parameters,cv=4, scoring='roc_auc',return_train_score=True)\n",
    "    tab = pd.DataFrame(clf.cv_results_)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    max_scores = tab.groupby(['param_max_depth','param_n_estimators']).max()\n",
    "    max_scores = max_scores.unstack()[['mean_test_score', 'mean_train_score']]\n",
    "    sns.heatmap(max_scores.mean_test_score, annot=True, fmt='.4g')\n",
    "    plt.title('Grid Search CV Score on Train and Test Data')\n",
    "    plt.show()\n",
    "    best_parameter= clf.best_params_\n",
    "    print('Best depth: ', clf.best_estimator_.max_depth)\n",
    "    print('Best n estimators: ', clf.best_estimator_.n_estimators)\n",
    "    #return clf\n",
    "\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "#clf = apply_random_forest()\n",
    "#clf.fit(X_train,y_train)\n",
    "#y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=X_train.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(12,15))\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_for_model(y_test,y_pred):\n",
    "    from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "get_metrics_for_model(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_df(test_dataframe):\n",
    "    check_data_missing_columns(test_dataframe)\n",
    "    numeric_df,non_numeric_df = get_numeric_and_non_numeric_columns(test_dataframe)\n",
    "    #check_value_counts(non_numeric_df)\n",
    "    #non_numeric_df = modification_in_destination_feature(non_numeric_df)\n",
    "    numeric_df = apply_scaling_numeric(numeric_df)\n",
    "    non_numeric_df = perform_onehot_encoding(non_numeric_df)\n",
    "    return generate_final_df(non_numeric_df,numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.Claim = clf.predict(run_test_df(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.Claim.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
